{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d08028c-be52-4d84-a995-34b690c3e8a5",
      "metadata": {
        "id": "3d08028c-be52-4d84-a995-34b690c3e8a5"
      },
      "source": [
        "# AnyoneAI - Project II\n",
        "\n",
        "# Making Predictions with NBA data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff2f3cb-7e1a-4705-bce7-44a56c0113e1",
      "metadata": {
        "id": "4ff2f3cb-7e1a-4705-bce7-44a56c0113e1"
      },
      "source": [
        "In our first project, we learned how to create our own datasets by using a public API, Python and Pandas. We're now going to explore how to make predictive models for regression and classification tasks using the Scikit Learn library"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b732b5b-8fcc-4917-85a1-035bfc00a7dd",
      "metadata": {
        "id": "5b732b5b-8fcc-4917-85a1-035bfc00a7dd"
      },
      "source": [
        "The goals of this project are:\n",
        "- Learn how to define a prediction task\n",
        "- Selecting evaluation metrics and baseline models\n",
        "- Perform feature engineering and standarization\n",
        "- Training and using predictive models: Univariable and Multivariate Linear Regression, Classification\n",
        "- Understand how Gradient Descent works by implementing a Linear Regressor in python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73bd1212-887d-4b10-a277-30156aaf410b",
      "metadata": {
        "id": "73bd1212-887d-4b10-a277-30156aaf410b",
        "tags": []
      },
      "source": [
        "## 1. Using Regression Models to Estimate players Salaries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e51670c9-30ec-4dcf-b3f4-e5ba90019818",
      "metadata": {
        "id": "e51670c9-30ec-4dcf-b3f4-e5ba90019818"
      },
      "source": [
        "A player's salary can be explained by a lot of factors: \n",
        "\n",
        "- Years in the league: NBA contracts are limited in price, players have caps on how much money they make depending on their years playing in the league\n",
        "- Age: Highly correlated to the previous one, NBA players have a minimun age of 19 years\n",
        "- Draft position: players out of USA universities are selected each year through a process called draft, in which each team selects a player in a predefined order for 2 rounds (meaning only 60 players are drafted each year). A rookie contract value depends on the draft position. (Undrafted players have to negotiate a salary independently)\n",
        "- Performance in statistical categories: after the rookie contract, players can negotiate freely with teams, and usually statistical categories like points, rebounds and assists are extremely important.  \n",
        "- Team: Even though there are limits to what all teams can expend in players salary, they all allocate their resources differently, and can be more willing to pay the penalties incurred by exceeding those limitations.\n",
        "- Year in which the contract was signed: the mininum and maximum values of contracts possibles in the NBA changes depending on league revenue (television contracts, sponsorships, etc), so if the amount of money the teams make increases, players can negotiate bigger contracts.\n",
        "- Intangibles: players can be valued also in things that are not easily translated to a statistic, good defensive players might not always have great stats but can be extremely important for a team, the same can be said about veteran players that help young ones to learn and are good locker-room guys.\n",
        "\n",
        "But we're going to take a simplified approach, we'll try to use the data we already have to make the best estimator possible, and then we will analyze what went right and what could've gone wrong with our results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f110fec-8919-4427-89f7-b3e581176703",
      "metadata": {
        "id": "6f110fec-8919-4427-89f7-b3e581176703"
      },
      "source": [
        "### Analyzing our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bafda55f-4831-49e4-abf6-cb8b2faf16ac",
      "metadata": {
        "id": "bafda55f-4831-49e4-abf6-cb8b2faf16ac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdac389b-e5f8-4563-a187-36b016c0641c",
      "metadata": {
        "id": "bdac389b-e5f8-4563-a187-36b016c0641c"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/anyoneai/notebooks/main/datasets/project2_players_df.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3cc6b89-e698-4943-8562-160190b9cbd0",
      "metadata": {
        "id": "c3cc6b89-e698-4943-8562-160190b9cbd0"
      },
      "source": [
        "Let's have another look at our previously generated dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e098b76d-c520-474b-9998-a263354fe27b",
      "metadata": {
        "id": "e098b76d-c520-474b-9998-a263354fe27b"
      },
      "source": [
        "1.1. Plot all players statistics (\"PTS\", \"REB\", \"AST\",\"STL\",\"BLK\") against salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d589f1-25c1-48f8-88f3-e2c7f0e72625",
      "metadata": {
        "id": "50d589f1-25c1-48f8-88f3-e2c7f0e72625"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bbf0fe81-4aed-4dd9-8500-0919b4ec1e07",
      "metadata": {
        "id": "bbf0fe81-4aed-4dd9-8500-0919b4ec1e07"
      },
      "source": [
        "1.2. What can we say about these distributions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b0fd30-0860-4ac3-8d52-5b072f1fd822",
      "metadata": {
        "id": "12b0fd30-0860-4ac3-8d52-5b072f1fd822"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "17735366-22bf-4cd8-a392-9dfb01652da0",
      "metadata": {
        "id": "17735366-22bf-4cd8-a392-9dfb01652da0"
      },
      "source": [
        "### Splitting the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02450fb0-829c-420b-b65c-ea553a9a81a2",
      "metadata": {
        "id": "02450fb0-829c-420b-b65c-ea553a9a81a2"
      },
      "source": [
        "1.3. Split the dataset into train and testing sets. Use the Sklearn function for train/test splitting. Make sure to set the random state for reproducibility.\n",
        "\n",
        "**Note:** Before using scikit-learn `train_test_split()`, separate your dataframe into features and labels. Assign your features to `X` variable and labels to `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d532e0fb-e478-48a0-971b-1ad1d428fe95",
      "metadata": {
        "id": "d532e0fb-e478-48a0-971b-1ad1d428fe95"
      },
      "outputs": [],
      "source": [
        "# TODO: Put here your features\n",
        "X = None\n",
        "# TODO: Put here your labels\n",
        "y = None\n",
        "\n",
        "# TODO: Now use train_test_split()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5TpInGhkR6fo",
      "metadata": {
        "id": "5TpInGhkR6fo"
      },
      "source": [
        "*Don't change anything in this cell, just make it run correctly*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YDyKX-LUR7Xo",
      "metadata": {
        "id": "YDyKX-LUR7Xo"
      },
      "outputs": [],
      "source": [
        "if X.SEASON_EXP[322] == 7 and y[255] == 1517981:\n",
        "  print('Success!')\n",
        "else:\n",
        "  raise ValueError('The draft categories are incorrect, please review your function')\n",
        "\n",
        "if X.shape == (429, 18) and y.shape == (429,):\n",
        "  print('Success!')\n",
        "else:\n",
        "  raise ValueError('Your features/labels shape is incorrect, please review your code')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aec0deb-7efe-438c-8a4a-39f940aeb474",
      "metadata": {
        "id": "6aec0deb-7efe-438c-8a4a-39f940aeb474"
      },
      "source": [
        "### Baseline Model and Evaluation Metric"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ca78ad-8dc1-4b13-99bd-27dcd138a809",
      "metadata": {
        "id": "40ca78ad-8dc1-4b13-99bd-27dcd138a809"
      },
      "source": [
        "In every project, we need a baseline model that implements a very simple algorithm or heuristic so we can compare our results with it. \n",
        "In this case, we could create a function that always returns the average player salary, evaluate that, and then compare the result with our modeling to see if we are improving. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71a7eb29-2bdf-4faf-93e9-3206dbc9cca2",
      "metadata": {
        "id": "71a7eb29-2bdf-4faf-93e9-3206dbc9cca2"
      },
      "source": [
        "We need an evaluation metric to see how well our models fit the data. For this project we will use [Mean Absolute Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error) as our regression evaluation metric, because it is a really simple metric to interpret. A lower value means the model performs better. \n",
        "\n",
        "For this particular problem, we will always round the value, as we don't need decimals for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cefd619d-e6b0-4e70-acf8-f0f4a90fe896",
      "metadata": {
        "id": "cefd619d-e6b0-4e70-acf8-f0f4a90fe896"
      },
      "source": [
        "1.4. Create a Baseline model class that implements  fit() and predict() methods. As this model will not consider any other variable, the fit method should only receive a list of all players salaries. The predict method should receive and iterable and return a numpy array with the same length but every element should have the same value (the average salary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee01164-1ef2-44dc-8baa-74b630444577",
      "metadata": {
        "id": "8ee01164-1ef2-44dc-8baa-74b630444577"
      },
      "outputs": [],
      "source": [
        "class BaselineModel():\n",
        "  \"\"\"\n",
        "  A baseline model that always returns the same value, the mean of the \n",
        "  players salary in the train data\n",
        "  \"\"\"\n",
        "  \n",
        "  def fit(self, y_train):\n",
        "    \"\"\"\n",
        "    Fit the training data. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    y_train: Union[pd.Series, np.ndarray]\n",
        "        a pandas series or numpy array containing salary information\n",
        "    \"\"\"\n",
        "      \n",
        "  \n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predict salaries \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X: Union[pd.DataFrame, pd.Series, np.ndarray]\n",
        "        a pandas series, dataframe or numpy array with the \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        a numpy array of the same length as X, with all elements equal to \n",
        "        the mean salary calculated in fit()\n",
        "    \"\"\"\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1a8134-48a4-4c66-84d2-39030242ef5f",
      "metadata": {
        "id": "6a1a8134-48a4-4c66-84d2-39030242ef5f"
      },
      "source": [
        "1.5. Evaluate the performance of our BaselineModel on the test set using mean_absolute_error from Sklearn (round the result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb72f39b-e7fc-4cd8-bd23-ee4407a80eed",
      "metadata": {
        "id": "fb72f39b-e7fc-4cd8-bd23-ee4407a80eed"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fc4dff42-e36c-478d-bfd3-7541f3f36f16",
      "metadata": {
        "id": "fc4dff42-e36c-478d-bfd3-7541f3f36f16"
      },
      "source": [
        "### Regression with a single variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9597b03-31fd-4a9c-8dad-9479666355cd",
      "metadata": {
        "id": "c9597b03-31fd-4a9c-8dad-9479666355cd"
      },
      "source": [
        "You're now going to start modeling data. We will start with a really simple approach, selecting just one variable, and doing a regression to see if we improve upon our baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af92eeac-cbfb-45cb-8626-246332c69624",
      "metadata": {
        "id": "af92eeac-cbfb-45cb-8626-246332c69624"
      },
      "source": [
        "1.6. Select the variable you think would provide the best fit. Perform feature scaling on this variable using a Sklearn scaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173f1211-95e2-4bcb-ba7d-a40c516b4c24",
      "metadata": {
        "id": "173f1211-95e2-4bcb-ba7d-a40c516b4c24"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1c490e55-2bff-4a06-a01e-c6859d7edb52",
      "metadata": {
        "id": "1c490e55-2bff-4a06-a01e-c6859d7edb52"
      },
      "source": [
        "1.7. Train a model with [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html) from Sklearn using the default parameters. Evaluate the model's performance on the test set using the selected metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d198ad-a601-4722-937b-3be52090c8d1",
      "metadata": {
        "id": "15d198ad-a601-4722-937b-3be52090c8d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e87147d9-5b57-4984-9f0d-e595cd6d15d3",
      "metadata": {
        "id": "e87147d9-5b57-4984-9f0d-e595cd6d15d3"
      },
      "source": [
        "1.8. Read the Sklearn documentation, and write a function that tries different configurations for the hyperparameters for training: epochs, learning rate and alpha. For each combination of parameters, evaluate the trained algorithm on the test set, then save the results of each hyperparameter combination, finally select the one that has the best MAE (meaning the lowest number) and print the combination and the MAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e1f26f4-1eb4-4ecc-bfc2-9d8583f00d0d",
      "metadata": {
        "id": "9e1f26f4-1eb4-4ecc-bfc2-9d8583f00d0d"
      },
      "outputs": [],
      "source": [
        "def search_best_hyperparameters(max_iter, eta0):\n",
        "  result = {\n",
        "    \"hyperparameters\": {\"max_iter\": None, \"eta0\": None}, \n",
        "    \"mae\": None\n",
        "  }\n",
        "  # Complete your code here\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95ffbb3b-d161-4a29-9c48-eaff18b82412",
      "metadata": {
        "id": "95ffbb3b-d161-4a29-9c48-eaff18b82412"
      },
      "outputs": [],
      "source": [
        "# Example list of hyperparameters values\n",
        "max_iter = [1000, 1000000]\n",
        "eta0 = [0.0001, 0.001, 0.01, 0.1]\n",
        "\n",
        "result = search_best_hyperparameters(max_iter, eta0)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776e0c7a-d592-4479-aec6-870edff61def",
      "metadata": {
        "id": "776e0c7a-d592-4479-aec6-870edff61def"
      },
      "source": [
        "1.9. Compare the results of the baseline, the SGDRegressor with default parameters and the one with the best combination of hyperparameters you could find. (replace variables with the ones you used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e520ef6-52ed-48dc-8450-03031f3a03a6",
      "metadata": {
        "id": "2e520ef6-52ed-48dc-8450-03031f3a03a6"
      },
      "outputs": [],
      "source": [
        "print(\"Mean Absolute Error for each model:\")\n",
        "print(f\"Baseline: {baseline_mae}\")\n",
        "print(f\"Default SGDRegressor: {default_mae}\")\n",
        "print(f\"Best SGDRegressor: {best_mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19e281ec-d578-496d-9f5d-897a2e1986a2",
      "metadata": {
        "id": "19e281ec-d578-496d-9f5d-897a2e1986a2"
      },
      "source": [
        "### Multivariable Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff24d36-439a-478f-b0de-0021223f6e99",
      "metadata": {
        "id": "4ff24d36-439a-478f-b0de-0021223f6e99"
      },
      "source": [
        "To improve our model, we will add more features to it. We will have to do some processing to our dataset to be able to use the data.\n",
        "We'll start with the following variables:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247f4716-496a-4040-9519-77f7a6839691",
      "metadata": {
        "id": "247f4716-496a-4040-9519-77f7a6839691"
      },
      "source": [
        "- Points\n",
        "- Rebounds\n",
        "- Assists\n",
        "- Blocks\n",
        "- Experience\n",
        "- Position\n",
        "- Draft Number\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7958f7ec-45a0-4deb-bb79-3daa756dbcca",
      "metadata": {
        "id": "7958f7ec-45a0-4deb-bb79-3daa756dbcca"
      },
      "source": [
        "1.10. Create a copy of the dataset generated in the first project that only has the following columns (and player id as an index) and name it mv_regression_df:\n",
        "\n",
        "[\"PTS\", \"REB\", \"AST\", \"BLK\", \"SEASON_EXP\", \"POSITION\", \"DRAFT_NUMBER\", \"SALARY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b265b4-d4e5-40a6-a9c3-cce920ecaa1b",
      "metadata": {
        "id": "64b265b4-d4e5-40a6-a9c3-cce920ecaa1b"
      },
      "outputs": [],
      "source": [
        "# TODO: Complete here\n",
        "mv_regression_df = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tMQzDak1Nk2i",
      "metadata": {
        "id": "tMQzDak1Nk2i"
      },
      "source": [
        "*Don't change anything in this cell, just make it run correctly*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l_gK5RQvJC0V",
      "metadata": {
        "id": "l_gK5RQvJC0V"
      },
      "outputs": [],
      "source": [
        "if mv_regression_df.shape == (429, 8):\n",
        "  print('Success!')\n",
        "else:\n",
        "  raise ValueError('The shape is incorrect, please review your function')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4865eb6e-d85d-4283-a67c-93df46a5b72e",
      "metadata": {
        "id": "4865eb6e-d85d-4283-a67c-93df46a5b72e"
      },
      "source": [
        "#### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec9b71e8-57aa-405a-8b3b-b0585a45d64d",
      "metadata": {
        "id": "ec9b71e8-57aa-405a-8b3b-b0585a45d64d"
      },
      "source": [
        "1.11. Binning the DRAFT_NUMBER feature. Draft position directly impacts salaries during the first few years, but second round players and undrafted players don't have guaranteed contracts. So we're gonna divide the bins like this: \n",
        "\n",
        "       - 1 to 15: firstround_lottery\n",
        "       - 15 to 30: firstround_non_lottery\n",
        "       - 30 to 60: second_round\n",
        "       - Undrafted: undrafted\n",
        "       \n",
        "Create a new column named DRAFT using these 4 categories. Drop the draft number column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea6afa9-7df8-446c-b134-c832f3ca27b7",
      "metadata": {
        "id": "3ea6afa9-7df8-446c-b134-c832f3ca27b7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "TcTtv0OoN9Ov",
      "metadata": {
        "id": "TcTtv0OoN9Ov"
      },
      "source": [
        "*Don't change anything in this cell, just make it run correctly*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E0mxpgq9K_eJ",
      "metadata": {
        "id": "E0mxpgq9K_eJ"
      },
      "outputs": [],
      "source": [
        "if mv_regression_df[\"DRAFT\"].iloc[34] == 'firstround_lottery' and mv_regression_df[\"DRAFT\"].iloc[105] == 'second_round':\n",
        "  print('Success!')\n",
        "else:\n",
        "  raise ValueError('The draft categories are incorrect, please review your function')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a55237-cb04-4c38-bef3-8c363f9dbe5c",
      "metadata": {
        "id": "37a55237-cb04-4c38-bef3-8c363f9dbe5c"
      },
      "source": [
        "1.12. Encode the categorical features: DRAFT, POSITION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c565394e-5d44-4418-a33b-eaa801062dbc",
      "metadata": {
        "id": "c565394e-5d44-4418-a33b-eaa801062dbc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0kqplv_vO4H3",
      "metadata": {
        "id": "0kqplv_vO4H3"
      },
      "source": [
        "*Don't change anything in this cell, just make it run correctly*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RvdSf5VcO5Y1",
      "metadata": {
        "id": "RvdSf5VcO5Y1"
      },
      "outputs": [],
      "source": [
        "if mv_regression_df[\"DRAFT_firstround_non_lottery\"].iloc[134] == 1 and mv_regression_df[\"POSITION_Forward\"].iloc[205] == 0:\n",
        "  print('Success!')\n",
        "else:\n",
        "  raise ValueError('The draft categories are incorrect, please review your function')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9816d9d4-b44d-4bb7-9cad-156daee9dc50",
      "metadata": {
        "id": "9816d9d4-b44d-4bb7-9cad-156daee9dc50"
      },
      "source": [
        "#### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb528f1-852e-428e-b97c-40b412985f98",
      "metadata": {
        "id": "1eb528f1-852e-428e-b97c-40b412985f98"
      },
      "source": [
        "1.13. Split the dataset into train and test. \n",
        "\n",
        "\n",
        "**Note 1:** Before using scikit-learn `train_test_split()`, separate your dataframe into features and labels. Assign your features to `X` variable and labels to `y`.\n",
        "\n",
        "**Note 2:** Remember to drop `DRAFT_NUMBER` column if you haven't done that before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7696efd0-94f8-49ce-846f-4fd24a01b0fd",
      "metadata": {
        "id": "7696efd0-94f8-49ce-846f-4fd24a01b0fd"
      },
      "outputs": [],
      "source": [
        "# TODO: Put here your features\n",
        "X = None\n",
        "# TODO: Put here your labels\n",
        "y = None\n",
        "\n",
        "# TODO: Now use train_test_split()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O_hN_VyuQhxt",
      "metadata": {
        "id": "O_hN_VyuQhxt"
      },
      "source": [
        "*Don't change anything in this cell, just make it run correctly*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R9r19mhiQiJh",
      "metadata": {
        "id": "R9r19mhiQiJh"
      },
      "outputs": [],
      "source": [
        "if X.BLK.iloc[353] == 0.1 and y.iloc[400] == 8729020:\n",
        "  print('Success!')\n",
        "else:\n",
        "  raise ValueError('The draft categories are incorrect, please review your function')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2540df8-ac16-4ad1-b8cf-028f566faa06",
      "metadata": {
        "id": "b2540df8-ac16-4ad1-b8cf-028f566faa06"
      },
      "source": [
        "1.14. Perform feature scaling in all the numerical features (\"PTS\", \"REB\", \"AST\", \"BLK\", \"SEASON_EXP\") except for draft number (which we will tackle next)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c1b356-8f74-4a20-8b9d-9dd61b6e3dec",
      "metadata": {
        "id": "94c1b356-8f74-4a20-8b9d-9dd61b6e3dec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7790c25a-b516-4e3f-b311-6e5b026bfb80",
      "metadata": {
        "id": "7790c25a-b516-4e3f-b311-6e5b026bfb80"
      },
      "source": [
        "1.15. Write a function to train a SGDRegressor model with the new dataset, trying different hyperparameters, and selecting the one that performs the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8642f3-895c-4d8d-85b7-80a087a0adef",
      "metadata": {
        "id": "7d8642f3-895c-4d8d-85b7-80a087a0adef"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "33d63bc7-448d-40a6-a314-6602c75e2284",
      "metadata": {
        "id": "33d63bc7-448d-40a6-a314-6602c75e2284"
      },
      "source": [
        "1.16. How did the model performed compared to our univariate models? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8dc264b-1fde-4de3-9099-a526210075fa",
      "metadata": {
        "id": "b8dc264b-1fde-4de3-9099-a526210075fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e9992197-563b-4a69-9cd7-97fcb9ee3677",
      "metadata": {
        "id": "e9992197-563b-4a69-9cd7-97fcb9ee3677",
        "tags": []
      },
      "source": [
        "### DecisionTreeRegressor\n",
        "\n",
        "It is possible that this problem might not be easily resolvable by a linear model, or that there could be better types of algorithms to tackle it. As an example, let's try with a very used algorithm, a Decision Tree.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61930247-d4b0-4bdf-ad98-a421457e2c4a",
      "metadata": {
        "id": "61930247-d4b0-4bdf-ad98-a421457e2c4a"
      },
      "source": [
        "1.17. Create new model using [DecisionTreeRegressor](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html) from scikit learn. We will use again all variables, and try different configuration for the following hyperparameters:\n",
        "\n",
        "- max_depth\n",
        "- min_samples_leaf\n",
        "- max_features\n",
        "\n",
        "These are all regularization hyperparameters for this algorithm. Read the documentation to get a better grasp of what each one does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d393cdae-c2d7-40a0-a518-19f007edb242",
      "metadata": {
        "id": "d393cdae-c2d7-40a0-a518-19f007edb242"
      },
      "outputs": [],
      "source": [
        "# List of hyperparameter example values\n",
        "max_depth = [5, 10, 15, 20, 50]\n",
        "min_samples_leaf = [2, 10, 20, 50]\n",
        "max_features = [5, 10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ef72fc-7386-433c-9725-2055f4016ae9",
      "metadata": {
        "id": "71ef72fc-7386-433c-9725-2055f4016ae9"
      },
      "source": [
        "1.18. Compare the results obtained with the best decision tree model against the baseline, default and the best params sgd regressors-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1084d8-97a4-4618-b4f4-0952e0b39f09",
      "metadata": {
        "id": "af1084d8-97a4-4618-b4f4-0952e0b39f09"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ce424a87-37af-470d-9a14-ec6ae2258eb1",
      "metadata": {
        "id": "ce424a87-37af-470d-9a14-ec6ae2258eb1"
      },
      "source": [
        "### Analyzing our results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed6c9746-ed98-4075-9a6a-adb24056d217",
      "metadata": {
        "id": "ed6c9746-ed98-4075-9a6a-adb24056d217"
      },
      "source": [
        "Based on what you found, and what you read about players salaries above, answer the following: "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e204456d-cb86-47a0-9c3c-6307d8a831fa",
      "metadata": {
        "id": "e204456d-cb86-47a0-9c3c-6307d8a831fa"
      },
      "source": [
        "1.19. Which kind of model worked better in this dataset, linear or non linear models? Do you have any hypothesis about why? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f384324-76df-435c-97f5-57ccfd25157a",
      "metadata": {
        "id": "7f384324-76df-435c-97f5-57ccfd25157a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f09e5c20-3f7b-4938-a1b3-34ada990f181",
      "metadata": {
        "id": "f09e5c20-3f7b-4938-a1b3-34ada990f181"
      },
      "source": [
        "1.20. Is there something else we could do to improve our results if wanted to make a more accurate model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9epaygXxJH-9",
      "metadata": {
        "id": "9epaygXxJH-9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "25e23c2a-a0bf-4d39-bc1b-9524107f3a02",
      "metadata": {
        "id": "25e23c2a-a0bf-4d39-bc1b-9524107f3a02",
        "tags": []
      },
      "source": [
        "## 2. Predicting players All-NBA selections"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26cd4fec-1b8b-4bfc-8024-dcdd5b8b803a",
      "metadata": {
        "id": "26cd4fec-1b8b-4bfc-8024-dcdd5b8b803a"
      },
      "source": [
        "In this section we're going to try to solve a different question:\n",
        "\n",
        "Can we train a model to predict which players are going to be selected to ALL-NBA teams at the end of the season? This is a [binary classification](https://en.wikipedia.org/wiki/Binary_classification) task, so we're training our first classifier model to solve this problem.\n",
        "\n",
        "Consider that:\n",
        "\n",
        "- Being selected as part of the [All-NBA teams](https://en.wikipedia.org/wiki/All-NBA_Team) is different than being selected for [All-Star Game](https://en.wikipedia.org/wiki/NBA_All-Star_Game). \n",
        "- You're trying to predict All-NBA selections, which takes place after the regular season but before playoffs start, so we're only going to use players and teams statistics about the regular season (you're not going to consider if the players got to the NBA finals for example). \n",
        "- All Star game takes place at the middle point of the regular season, players are selected based on partial season performance, and the general public has 50% of the votes, so it is also a more popularity-based award.\n",
        "- All-NBA teams are divided in first, second and third teams of 5 players each, divided by position: 2 front court players (guards), 2 backcourt players (forwards) and 1 center.\n",
        "- As only 15 players are selected to All-NBA teams each year (out of more than 400 qualifying players), our dataset is going to be imbalanced. You're going to have to find a good strategy to deal with this inbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef2353fa-10d7-48d1-85d7-f8743ee86698",
      "metadata": {
        "id": "ef2353fa-10d7-48d1-85d7-f8743ee86698"
      },
      "source": [
        "### Analyzing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4159ce5-fec3-48bb-93c5-058f2cbb55c5",
      "metadata": {
        "id": "d4159ce5-fec3-48bb-93c5-058f2cbb55c5"
      },
      "source": [
        "To do this task, you're going to need historical information about All-NBA selections. We'll use a dataset that contains information about players from season starting in 1983 and ending in the 2018-2019 season.\n",
        "The dataset contains statistics for all players, and a column named \"all-nba\" that is going to be our target variable, 1 means the player was selected to an All-NBA team that season.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6d64103-d6b5-4544-8ca5-81f99c937d73",
      "metadata": {
        "id": "e6d64103-d6b5-4544-8ca5-81f99c937d73"
      },
      "source": [
        "2.1. Load the dataset \"all_nba_1983_2017_dataset.csv\" from disk, look at the data inside it and print:\n",
        "- number of rows\n",
        "- number of seasons\n",
        "- number of unique players\n",
        "- number of all-nba selections vs non selected "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb6725f6-418d-4159-b046-3bf33a8ead0b",
      "metadata": {
        "id": "bb6725f6-418d-4159-b046-3bf33a8ead0b"
      },
      "outputs": [],
      "source": [
        "all_nba_df = pd.read_csv(\"https://raw.githubusercontent.com/anyoneai/notebooks/main/datasets/all_nba_1983_2017_dataset.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f268db59-8c9e-446b-be19-290e608169d2",
      "metadata": {
        "id": "f268db59-8c9e-446b-be19-290e608169d2"
      },
      "source": [
        "### Splitting the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4916b2-e8cf-4e30-a2ac-e1538c2f5cd5",
      "metadata": {
        "id": "6b4916b2-e8cf-4e30-a2ac-e1538c2f5cd5"
      },
      "source": [
        "2.2. Split the dataset in training and test sets. Make sure to keep the distribution of values in the target variable.\n",
        "\n",
        "Use columns: 'team', 'games', 'games_started', 'mp', 'fg_perc', '3p_perc',\n",
        "       '2p_perc', 'ft_perc', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts','all_nba'.\n",
        "\n",
        "**Note:** Assign your features to `X` variable and labels to `y`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25cfc4ee-98e7-4b84-98d3-80a91fb44912",
      "metadata": {
        "id": "25cfc4ee-98e7-4b84-98d3-80a91fb44912"
      },
      "outputs": [],
      "source": [
        "# TODO: Put here your features\n",
        "X = None\n",
        "# TODO: Put here your labels\n",
        "y = None\n",
        "\n",
        "# TODO: Now use train_test_split()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KpgcmrW6JX_d",
      "metadata": {
        "id": "KpgcmrW6JX_d"
      },
      "source": [
        "*Don't change anything in this cell, just make it run correctly*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N2S6tsHUJXdm",
      "metadata": {
        "id": "N2S6tsHUJXdm"
      },
      "outputs": [],
      "source": [
        "if X.shape == (14825, 15) and y.shape == (14825,):\n",
        "  print('Success!')\n",
        "else:\n",
        "  raise ValueError('Your features/labels shape is incorrect, please review your code')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7043db6e-da74-4a04-91d9-4dd0cd830f22",
      "metadata": {
        "id": "7043db6e-da74-4a04-91d9-4dd0cd830f22"
      },
      "source": [
        "### Baseline model and Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cedaf085-2a23-41ab-a55f-474e2ae6bb9c",
      "metadata": {
        "id": "cedaf085-2a23-41ab-a55f-474e2ae6bb9c"
      },
      "source": [
        "In this oportunity we'll define our baseline model as the model we can train with the minimun amount of work on the dataset. For this you're gonna train a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) with default parameters, and without doing any preprocessing to our data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a8999b-2dfe-466b-814c-94ecced9f8dc",
      "metadata": {
        "id": "67a8999b-2dfe-466b-814c-94ecced9f8dc"
      },
      "source": [
        "2.3. Let's start with a simple test. What accuracy would we get if we had a baseline model that always predicted 0 (player not selected to all nba)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa3bbfb-d2ce-43bc-aea4-f6f7aab0933c",
      "metadata": {
        "id": "4aa3bbfb-d2ce-43bc-aea4-f6f7aab0933c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a7f436a6-d3fe-4ead-8c09-b450d850b36f",
      "metadata": {
        "id": "a7f436a6-d3fe-4ead-8c09-b450d850b36f"
      },
      "source": [
        "2.4. What does this tells us about the data and the use of accuracy as an evaluation metric?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de87d7c-4f0e-4ffc-b063-cee6eadc4e16",
      "metadata": {
        "id": "6de87d7c-4f0e-4ffc-b063-cee6eadc4e16"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "df1a22d1-3fd1-4e6f-9139-52a3466fb1c4",
      "metadata": {
        "id": "df1a22d1-3fd1-4e6f-9139-52a3466fb1c4"
      },
      "source": [
        "2.5. Scale all numerical features in the dataset (we will keep this scaling for future modeling, so make sure to do it in place)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d2a505-f193-4b94-89c3-56cba2c4db54",
      "metadata": {
        "id": "e4d2a505-f193-4b94-89c3-56cba2c4db54"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0ccfd642-fd2a-4ce6-af92-901156e2a009",
      "metadata": {
        "id": "0ccfd642-fd2a-4ce6-af92-901156e2a009"
      },
      "source": [
        "2.6. Train a LogisticRegression with default parameters, use only the numerical features (omit the team information for now). This will be our baseline model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f9ffef5-6333-481e-816f-9125c95fe117",
      "metadata": {
        "id": "6f9ffef5-6333-481e-816f-9125c95fe117"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0f06758a-f2dd-4339-b170-275b428fdb4e",
      "metadata": {
        "id": "0f06758a-f2dd-4339-b170-275b428fdb4e"
      },
      "source": [
        "2.7. Evaluate our baseline model using this metrics: \n",
        "\n",
        "    - accuracy\n",
        "    - precision\n",
        "    - recall\n",
        "    - f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b953324f-f7ae-4823-a801-f06d27d6eb43",
      "metadata": {
        "id": "b953324f-f7ae-4823-a801-f06d27d6eb43"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7a540e7b-387d-4e2b-a441-d0c5173bdbf7",
      "metadata": {
        "id": "7a540e7b-387d-4e2b-a441-d0c5173bdbf7"
      },
      "source": [
        "From now on, you'll be evaluating you model primarily using the F1 Score metric, but we also want to avoid models that have very low recall. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2054a43f-55ec-45fc-9ead-a7699d8aa2b0",
      "metadata": {
        "id": "2054a43f-55ec-45fc-9ead-a7699d8aa2b0"
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e2847f3-f02c-4308-8a0c-41ba79af0781",
      "metadata": {
        "id": "1e2847f3-f02c-4308-8a0c-41ba79af0781"
      },
      "source": [
        "#### Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27b6ddb3-576c-4238-9ec3-534aafee764b",
      "metadata": {
        "id": "27b6ddb3-576c-4238-9ec3-534aafee764b"
      },
      "source": [
        "2.8. One hot encode the Team feature. Make sure to drop the original column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ca83ec-7aab-4cff-8ac7-1b224ff54dde",
      "metadata": {
        "id": "f4ca83ec-7aab-4cff-8ac7-1b224ff54dde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6592c6c0-7ec8-49ac-936c-2d0fb84ccfef",
      "metadata": {
        "id": "6592c6c0-7ec8-49ac-936c-2d0fb84ccfef",
        "tags": []
      },
      "source": [
        "#### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06240cb2-de21-4d4e-ae0e-0f90c3c0453a",
      "metadata": {
        "id": "06240cb2-de21-4d4e-ae0e-0f90c3c0453a"
      },
      "source": [
        "2.9. Train a logistic regresion model, find the best hyperparameters for: tols, C and max_iter. Try at least 4 values of each parameter. Remember to select based on f1 score, but report also precision and recall. Save the best performing model to use in the next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bdc4abf-ded3-4d8b-9170-c1d5b4951ba7",
      "metadata": {
        "id": "4bdc4abf-ded3-4d8b-9170-c1d5b4951ba7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "45c0c3bd-b431-40f1-abbb-4e90b7479411",
      "metadata": {
        "id": "45c0c3bd-b431-40f1-abbb-4e90b7479411"
      },
      "source": [
        "#### Evaluating on New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5352ce-df8a-4c9d-b583-65255774f9d9",
      "metadata": {
        "id": "3a5352ce-df8a-4c9d-b583-65255774f9d9"
      },
      "source": [
        "You're now going to evaluate the results on a test dataset that has not being used to train or do hyperparameter tuning, this is sometimes known as a Test set (in this cases the test set used for training is known as validation set, yeah, it's confusing, but you can read about it [here](https://machinelearningmastery.com/difference-test-validation-datasets/))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9da9e93b-6265-44e4-89be-75e7178800e2",
      "metadata": {
        "id": "9da9e93b-6265-44e4-89be-75e7178800e2"
      },
      "source": [
        "2.10. Load the dataset [all_nba_2018_dataset.csv](https://raw.githubusercontent.com/anyoneai/notebooks/main/datasets/all_nba_2018_dataset.csv) in one dataframe and [all_nba_2018_selections.csv](https://raw.githubusercontent.com/anyoneai/notebooks/main/datasets/all_nba_2018_selections.csv)) in another, then:\n",
        "\n",
        "    - Scale the numerical features. Columns season_id, player_id, player_season, player, season and season_start will not be used for prediction, you can keep them but remember not to pass them to the classifier.\n",
        "    \n",
        "    - Create the one hot encoded features for team. This step will be complex, as you will have to consider that in the 2018 season there are 30 teams, but the previous dataset contains 40 teams, that is because a lot of teams changed names or cities over the years. You need to add those 10 different team names in this dataset (with all values in 0) to make the classifier work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79ea153a-b061-4df9-9c3d-1aaa0526c700",
      "metadata": {
        "id": "79ea153a-b061-4df9-9c3d-1aaa0526c700"
      },
      "outputs": [],
      "source": [
        "all_nba_2018_df = pd.read_csv(\"https://raw.githubusercontent.com/anyoneai/notebooks/main/datasets/all_nba_2018_dataset.csv\", index_col=0)\n",
        "all_nba_2018_selections = pd.read_csv(\"https://raw.githubusercontent.com/anyoneai/notebooks/main/datasets/all_nba_2018_selections.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-1VYrr5IV8TH",
      "metadata": {
        "id": "-1VYrr5IV8TH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "aeBb8Zha2FAQ",
      "metadata": {
        "id": "aeBb8Zha2FAQ"
      },
      "source": [
        "*Don't change anything in this cell, just make it run correctly*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y7fgqGQL2F5R",
      "metadata": {
        "id": "Y7fgqGQL2F5R"
      },
      "outputs": [],
      "source": [
        "if all_nba_2018_df.shape == (530, 54):\n",
        "  print('Success!')\n",
        "else:\n",
        "  raise ValueError('The shape is incorrect, please review your function')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b0bb296-b1b3-4ae4-b199-b11224c78a82",
      "metadata": {
        "id": "8b0bb296-b1b3-4ae4-b199-b11224c78a82"
      },
      "source": [
        "2.11. Predict and evaluate the model using precision, recall and f1 score. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00ddffa-3f09-4294-beb5-098c2d698af0",
      "metadata": {
        "id": "b00ddffa-3f09-4294-beb5-098c2d698af0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "be98174e-4d1b-407d-8ecc-dd568f6e5368",
      "metadata": {
        "id": "be98174e-4d1b-407d-8ecc-dd568f6e5368"
      },
      "source": [
        "2.12. Analyze the results, what do you think it is happening?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17f87aa8-dd84-462a-b26b-80400e4a87e3",
      "metadata": {
        "id": "17f87aa8-dd84-462a-b26b-80400e4a87e3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "77a8c607-5df7-43d2-8365-cbbb6f2b93e1",
      "metadata": {
        "id": "77a8c607-5df7-43d2-8365-cbbb6f2b93e1"
      },
      "source": [
        "#### Creating our custom Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21dc0d0a-1d15-4f9e-b3ed-f83df1f51ce0",
      "metadata": {
        "id": "21dc0d0a-1d15-4f9e-b3ed-f83df1f51ce0"
      },
      "source": [
        "One thing to consider in this problem, is that the number of ALl NBA selections is fixed each year, a total of 15 players are always selected. But our current model does not limit the number of positive classified players. So, we will have to wrap our model in a custom classifier that only returns as positive the 15 players with the higher probabilities. \n",
        "Fortunately, our chosen model provides access to the underlying probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22326d3-c1ae-475b-9b31-7b02876f8bbc",
      "metadata": {
        "id": "e22326d3-c1ae-475b-9b31-7b02876f8bbc"
      },
      "source": [
        "2.13. Using the trained model, predict probabilities for all rows in the dataset, and create a new column that has the probability that the player was selected as all nba. Round the probability to 3 decimals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fddf0631-d676-485d-9748-a688e854c9f2",
      "metadata": {
        "id": "fddf0631-d676-485d-9748-a688e854c9f2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c1e5edbf-faee-4773-a114-eed5eab89242",
      "metadata": {
        "id": "c1e5edbf-faee-4773-a114-eed5eab89242"
      },
      "source": [
        "2.14. Sort the dataset by probabilities and show the 15 players with higher probability to have been selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42562785-2d0d-4e11-a31f-3eca3f78c818",
      "metadata": {
        "id": "42562785-2d0d-4e11-a31f-3eca3f78c818"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1c27683b-0256-40c5-929c-d5ed6cdf6d1f",
      "metadata": {
        "id": "1c27683b-0256-40c5-929c-d5ed6cdf6d1f"
      },
      "source": [
        "2.15. Print:\n",
        "\n",
        "    - Players actually selected from the all_nba_2018_selections dataset,\n",
        "    - Players actually selected missing from OUR predictions+\n",
        "    - Players in our predictions not selected "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbcdcac-43bd-4936-8312-456b3b0bd842",
      "metadata": {
        "id": "fdbcdcac-43bd-4936-8312-456b3b0bd842"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "66b994d0-d37a-43c2-a38f-ea5e86afa512",
      "metadata": {
        "id": "66b994d0-d37a-43c2-a38f-ea5e86afa512"
      },
      "source": [
        "2.16. Create a class named AllNbaSingleSeasonClassifier that takes a scikit learn model in the constructor, then implements a predict method that returns predictions with only the 15 most probable selections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc85317-ffc5-45e9-8740-3703b5d1aa86",
      "metadata": {
        "id": "5fc85317-ffc5-45e9-8740-3703b5d1aa86"
      },
      "outputs": [],
      "source": [
        "class AllNbaSingleSeasonClassifier():\n",
        "  def __init__(self, model):\n",
        "    \"\"\"\n",
        "    Class constructor\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model: BaseEstimator\n",
        "      a Scikit learn estimator\n",
        "    \"\"\"\n",
        "    self._model = model\n",
        "      \n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predicts all nba selections. This classifier will limit the number\n",
        "    of positive instances to 15\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X: pd.DataFrame\n",
        "      a dataframe with the players data\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "      An array of the same length as y, with 15 true results based on the players with most probabilities of\n",
        "      beign selected\n",
        "    \"\"\"\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d83848f-8132-4205-bc18-88b8a5f07555",
      "metadata": {
        "id": "0d83848f-8132-4205-bc18-88b8a5f07555"
      },
      "source": [
        "2.17. Use the new classifier to make predictions and evaluate the result with precision, recall and f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac440daa-8a05-4a90-8729-a48af57092bb",
      "metadata": {
        "id": "ac440daa-8a05-4a90-8729-a48af57092bb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1dd382f9-9640-47ce-a077-41c8baeb2d9f",
      "metadata": {
        "id": "1dd382f9-9640-47ce-a077-41c8baeb2d9f",
        "tags": []
      },
      "source": [
        "#### Analyzing our results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4eb9454-b0d5-40f0-8cb3-0af1ce8ade34",
      "metadata": {
        "id": "f4eb9454-b0d5-40f0-8cb3-0af1ce8ade34"
      },
      "source": [
        "2.18. What do you think it is the main problem with this dataset and the way we trained our model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbefca3-c863-4cf6-a3a3-5168ef05e43f",
      "metadata": {
        "id": "4bbefca3-c863-4cf6-a3a3-5168ef05e43f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e81ac1ea-75ab-4fee-8148-20a4ea663791",
      "metadata": {
        "id": "e81ac1ea-75ab-4fee-8148-20a4ea663791"
      },
      "source": [
        "2.19. What do you think we could do to improve our model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f31b42-26bd-4ce4-a42d-1ceb75ba90b6",
      "metadata": {
        "id": "b8f31b42-26bd-4ce4-a42d-1ceb75ba90b6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0557c3f5-0e87-4a33-a1dc-fc20dd7d8fd7",
      "metadata": {
        "id": "0557c3f5-0e87-4a33-a1dc-fc20dd7d8fd7"
      },
      "source": [
        "### Optional: Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0089fbf9-0625-4446-bf45-d00da9063b14",
      "metadata": {
        "id": "0089fbf9-0625-4446-bf45-d00da9063b14"
      },
      "source": [
        "2.19. Read about oversampling techniques, for example [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html). Use this strategy to create synthetic data and retrain our model. Compare the results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51a4b48d-cf26-4f14-a478-3b0afa8501dc",
      "metadata": {
        "id": "51a4b48d-cf26-4f14-a478-3b0afa8501dc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8b1ee0ca-0d33-490c-9725-638fbd001f02",
      "metadata": {
        "id": "8b1ee0ca-0d33-490c-9725-638fbd001f02"
      },
      "source": [
        "## 3. Optional: Developing a Linear Regressor class from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6d261c-5372-447d-afdf-820aaf3fef26",
      "metadata": {
        "id": "aa6d261c-5372-447d-afdf-820aaf3fef26"
      },
      "source": [
        "Our last task will be to code a Linear Regression algorithm using Gradient Descent as its optimization algorithm in Python. The structure of the class is presented below, you should use numpy for numerical computation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aebe22f-3a17-4404-a12f-918da6a26237",
      "metadata": {
        "id": "8aebe22f-3a17-4404-a12f-918da6a26237"
      },
      "source": [
        "3.1. Write a LinearRegression class that implements fit and predict methods, and uses gradient descent as optimization algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4326a55-6896-466d-9d60-3b2667e20de6",
      "metadata": {
        "id": "b4326a55-6896-466d-9d60-3b2667e20de6"
      },
      "outputs": [],
      "source": [
        "    \n",
        "class LinearRegressor:\n",
        "  \"\"\"Linear regression algorithm class. Implements gradient descent as optimization algorithm\"\"\"\n",
        "  \n",
        "  def __init__(self, epochs: int, learning_rate: float):\n",
        "    \"\"\"\n",
        "    Class constructor\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    epochs: int\n",
        "      number of epochs to run gradient descent\n",
        "    learning_rate: float\n",
        "      rate of update of the gradients\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  def _gradient_descent():\n",
        "    \"\"\"\n",
        "    Gradient descent algorithm\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\"\n",
        "    Fit the model according to the given training data.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X: np.ndarray\n",
        "    y: np.ndarray\n",
        "    \"\"\"\n",
        "            \n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predict\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X: np.ndarray\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "      array with predictions\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7ce501-ef88-4345-8b27-e04914658bf4",
      "metadata": {
        "id": "8f7ce501-ef88-4345-8b27-e04914658bf4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ac25e809-7bdf-4dfa-896a-bc4cb8964f94",
      "metadata": {
        "id": "ac25e809-7bdf-4dfa-896a-bc4cb8964f94"
      },
      "source": [
        "3.2. Train a regression model with the data from the first section to calculate players salaries using points per game. Try with a few different values (3 or 4 for each should suffice) for epochs and learning rate parameters, calculate MAE for all results and save the best result along with the parameters values used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1c2fe9-e67a-4399-95a1-81cbed3ada45",
      "metadata": {
        "id": "de1c2fe9-e67a-4399-95a1-81cbed3ada45"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ea78cfff-1216-486f-bd1e-7e42127c029d",
      "metadata": {
        "id": "ea78cfff-1216-486f-bd1e-7e42127c029d"
      },
      "source": [
        "3.3. Evaluate the model performance on the test set, and compare with the result you obtained using SGDRegressor from scikit-learn."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}